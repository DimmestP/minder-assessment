{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "185d7ed2-ec54-48fb-b498-6f2009ad6898",
   "metadata": {},
   "source": [
    "# Developing a classifier for houses of multiple or single occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b5071f-c8e2-4d46-b2a7-cd5c0c152e03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load required python libraries\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.api import VAR\n",
    "import matplotlib.pyplot as plt\n",
    "from functions import count_events_per_interval, fit_VAR_model\n",
    "\n",
    "# There is a pandas FutureWarning about using catagorical variables in groupby. Pandas will address this in future updates.\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Attach sqlite data base\n",
    "connection = sqlite3.connect(\"../data/data.db\")\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d337fb7-8dd4-47ed-ad51-54a4799f3c60",
   "metadata": {},
   "source": [
    "## Import data from Sqlite database to pandas data frame\n",
    "Sqlite database consists of two tables; homes and motion. The total database is only about 60 Mb in size so it can be loaded straight into memory (via a pandas dataframe) without overflow concerns.\n",
    "\n",
    "### homes\n",
    "\n",
    "homes holds whether the home is a single or multiple occupancy house.\n",
    "\n",
    "- id is the unique house id, renamed home_id (32 hexadecimal)\n",
    "- multiple_occupancy is whether house is occupied by more than one person (boolean)\n",
    "\n",
    "### motion\n",
    "\n",
    "motion holds each motion detection event as a tuple with four entries\n",
    "\n",
    "- id is the unique event id, renamed event_id (32 hexadecimal)\n",
    "- home_id is the unique home id (hexadecimal)\n",
    "- datetime is the time of the motion detection event (YYYY-MM-DD HH:MM:SS+ss)\n",
    "- location is the room of house that the motion was detected in (category: living room, conservatory, dining room, study, WC1, hallway, bathroom1, kitchen, lounge, bedroom1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefe6833-4364-443d-b313-62ec59fa99b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "homes = pd.read_sql_query(\"SELECT * FROM homes\", connection)\n",
    "\n",
    "# Specify multiple_occupancy as boolean\n",
    "homes[\"multiple_occupancy\"]=homes[\"multiple_occupancy\"].astype('bool')\n",
    "\n",
    "# Change id to home_id to be consistent and specific\n",
    "homes = homes.rename(columns={\"id\":\"home_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de07d82-b0c4-488e-98c7-92f06b27fd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion = pd.read_sql_query(\"SELECT * FROM motion\", connection)\n",
    "\n",
    "# Specify datetime should be a datetime variable\n",
    "motion[\"datetime\"] = pd.to_datetime(motion[\"datetime\"])\n",
    "\n",
    "# Specify location should be a category (This gives a FutureWarning in groupby commands that pandas will address soon)\n",
    "motion[\"location\"] = motion[\"location\"].astype('category')\n",
    "\n",
    "# Change id to event_id to be consistent and specific\n",
    "motion = motion.rename(columns={\"id\":\"event_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd972f64-2181-4fef-9f2b-7491cb6d1f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_homes_join = pd.read_sql_query(\"\"\"SELECT motion.id as `event_id`, motion.home_id, motion.datetime, motion.location, homes.multiple_occupancy\n",
    "FROM motion\n",
    "INNER JOIN homes ON motion.home_id=homes.id;\"\"\", connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0c6834-414f-4398-9a3f-d69e7c336a02",
   "metadata": {},
   "source": [
    "## Initial data exploration\n",
    "\n",
    "- **is there any missing data** No detected null/na values in imported data.\n",
    "- **do all home_id's have entries in both tables?**     Of the 106 unique homes in the home data set, there are only 50 unique homes with motion data.\n",
    "- **are all the events unique?**     There are 580317 events, every event has a unique id.\n",
    "- **do all homes have the same rooms?**     No, between 2 and 8.\n",
    "- **are location names unique?** No, mosts homes have lounges but 3 have lounges and living rooms. Most bathrooms, 2 only have WC, some have both.\n",
    "- **do the events cover the same time period?** Mosts homes have events covering the time period 1st Jan 2024 until 31st Jan 2024. However, one home only has seven days worth of data.\n",
    "- **are there similar number of events per house?** No, 1000< x <30,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb554329-9e42-42ee-af49-9edb9b44a8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "homes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13f16e5-7485-426d-9af2-b6d4190347a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86548429-20fe-4e1d-9df4-47c348a9fcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_homes_join.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bc7334-186f-4f5f-9a55-a8920fe2be87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique home_ids in homes table: \", len(homes[\"home_id\"].unique()))\n",
    "print(\"Number of unique home_ids in motion table: \", len(motion[\"home_id\"].unique()))\n",
    "print(\"Number of unique home_ids in motion-homes combined: \", len(motion_homes_join[\"home_id\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d73d686-5889-4423-abc2-1c7b816c2867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all home ids are 32 digit hexadecimals\n",
    "print(\"All home_id's in the homes table are 32 digit hexadecimals:\",len(homes[\"home_id\"]) == sum(homes.home_id.str.match(\"[0-9abcdef]{32}\")))\n",
    "print(\"All home_id's in the motion table are 32 digit hexadecimals:\",len(motion[\"home_id\"]) == sum(motion.home_id.str.match(\"[0-9abcdef]{32}\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e84feff-b3f9-47c8-8772-4f2708eb4e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all event ids are 32 digit hexadecimals\n",
    "print(\"All event_id's in the motion table are 32 digit hexadecimals:\",len(motion[\"home_id\"]) == sum(motion.event_id.str.match(\"[0-9abcdef]{32}\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d089b3f-ce98-4831-9ff0-67021ad0774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique event_ids in motion table: \", len(motion[\"event_id\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da24c9-390c-4817-b646-96798903c5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms_per_home = motion[[\"home_id\",\"location\"]].groupby([\"home_id\",\"location\"]).head(1).groupby([\"home_id\"]).count()\n",
    "print(\"Homes have between \",min(rooms_per_home[\"location\"]),\" and \",max(rooms_per_home[\"location\"]),\" rooms.\")\n",
    "events_per_home = motion[[\"home_id\",\"event_id\"]].groupby([\"home_id\"]).count()\n",
    "print(\"Homes have between \",min(events_per_home[\"event_id\"]),\" and \",max(events_per_home[\"event_id\"]),\" events.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f67e2af-2600-4481-a922-5d158e6b795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of houses with each room type:\")\n",
    "motion[[\"home_id\",\"location\"]].groupby([\"home_id\",\"location\"]).head(1).groupby([\"location\"]).count().sort_values(\"home_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6edc0e-fd65-4281-be88-8abdbada1abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of events per room type:\")\n",
    "motion[[\"location\",\"event_id\"]].groupby([\"location\"]).count().sort_values(\"event_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd69ae53-24dd-4988-8e3c-3976ecaabbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "homes_with_living_rooms = motion[motion.location == \"living room\"][\"home_id\"].unique()\n",
    "homes_with_lounges = motion[motion.location == \"lounge\"][\"home_id\"].unique()\n",
    "print(len(list(set(homes_with_living_rooms) & set(homes_with_lounges))), \"homes have living rooms and lounges\")\n",
    "print(\"42 homes only have a lounge\")\n",
    "print(\"No homes only have a living room\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece03c6c-fc26-406b-904e-4de36227495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "homes_with_WC = motion[motion.location == \"WC1\"][\"home_id\"].unique()\n",
    "homes_with_bathrooms = motion[motion.location == \"bathroom1\"][\"home_id\"].unique()\n",
    "print(len(list(set(homes_with_bathrooms) & set(homes_with_WC))), \"homes have bathroom and water closets\")\n",
    "print(\"2 homes only have water closets\")\n",
    "print(\"29 homes only have bathrooms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfb2263-4d81-4ac0-b8d4-5d4f70ffb21b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Time period of sensor acquisition\n",
    "home_sensor_last_entry = motion[[\"home_id\",\"datetime\"]].groupby(\"home_id\").max().rename(columns={\"datetime\":\"enddate\"})\n",
    "home_sensor_first_entry = motion[[\"home_id\",\"datetime\"]].groupby(\"home_id\").min().rename(columns={\"datetime\":\"startdate\"})\n",
    "home_sensor_last_first_combined = pd.merge(home_sensor_first_entry, home_sensor_last_entry, on=\"home_id\")\n",
    "home_sensor_last_first_combined[\"difference\"] = home_sensor_last_first_combined[\"enddate\"] - home_sensor_last_first_combined[\"startdate\"]\n",
    "print(\"The shorted period of sensor data is: \", min(home_sensor_last_first_combined[\"difference\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6f187b-0d48-4b1e-b752-99010ee0af3b",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "To simplify the time series modelling I am going to remove all the event data associated with living room and WC1 locations. All but two homes will still have sensor data in similar rooms. Further exploration is required to determine if these location labels are errors or if these are large homes with multiple receptions rooms/ensuites or if there are multiple sensors in the same rooms. If model performance in these homes is poor we can return to this assumption.\n",
    "\n",
    "Only a handful of homes have studies/conservatories/dining rooms. For this exploratory analysis I am not going to fit time series models to these data sets. I will add binary labels \"has study\", \"has conservatory\", \"has dining rooms\" as this suggests larger houses with possible multiple occupants. This will give the ML classification some extra data. If model performance in these homes is poor we can return to this assumption.\n",
    "\n",
    "In order to facilitate the fitting of time series models, I will convert the events based recording to events per 1 day intervals across the entire month of Janurary. I am going to remove the homes with recording periods less than 20 days worth of events detected. The time series models used run on a rolling average. The sensor may have only been installed on the 24th of Jan for one house. The other may have gone on holiday from the 16th, for example. The model will not be able to account for such behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edff73e9-6b68-4cdf-862f-2f9702d62a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rooms and rooms found in less than 10 homes\n",
    "events_selected_locations = motion[motion.location.str.contains('bedroom1|lounge|bathroom1|hallway|kitchen')]\n",
    "\n",
    "# Remove the two homes with less than 20 days worth of data\n",
    "events_selected_locations_homes = events_selected_locations[~events_selected_locations.home_id.str.contains('df9f7afaae7821246e296a41e9e2a6b4|15663392d490688cd4b0e5aa3d5b6ef3')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b66745a-636d-4de2-9b86-aed2bbf8508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "homes_with_binary_locations = motion[motion.location.str.contains('conservatory|dining room|study')][[\"home_id\",\"location\"]].groupby([\"home_id\", \"location\"]).head(1)\n",
    "\n",
    "homes_with_binary_locations[\"has_conservatory\"] = homes_with_binary_locations[\"location\"] == \"conservatory\"\n",
    "\n",
    "homes_with_binary_locations[\"has_dining_room\"] = homes_with_binary_locations[\"location\"] == \"dining room\"\n",
    "\n",
    "homes_with_binary_locations[\"has_study\"] = homes_with_binary_locations[\"location\"] == \"study\"\n",
    "\n",
    "homes_with_binary_locations = homes_with_binary_locations.drop(columns = \"location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab0be53-8d5d-450a-a93b-9c8fa4524cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any homes still have any time series data post-filter\n",
    "events_per_home_post_filter = events_selected_locations_homes[[\"home_id\",\"event_id\"]].groupby([\"home_id\"]).count()\n",
    "print(\"Homes have between \",min(events_per_home_post_filter[\"event_id\"]),\" and \",max(events_per_home_post_filter[\"event_id\"]),\" events.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbc9c80-5ad1-4a56-a329-0a5d45406f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FutureWarning is unactionable and will be solved by pandas team in future\n",
    "counted_events_per_house = events_selected_locations_homes.groupby([\"home_id\",\"location\"]).apply(count_events_per_interval, start = \"2024-01-01\", end = \"2024-02-01\", interval = \"1d\", include_groups=False)\n",
    "\n",
    "# Tidy up dataframe index\n",
    "counted_events_per_house = counted_events_per_house.reset_index(level=['home_id','location']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0743e14-8388-45b6-b01a-ec5e1e8838f1",
   "metadata": {},
   "source": [
    "## Time Series Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ff7797-93f8-487c-8973-e173bcb73a80",
   "metadata": {},
   "source": [
    "A time series model will be fitted to the sensor data of the 5 room types that are common to most homes. The events are discrete integers always greater than 1. Ideally a poisson or neg-bin model should be used for this data. However, a vector autoregressive model with poisson noise would have to be developed (there are limited available python packages for this). \n",
    "\n",
    "Instead, I will use a more common vector autoregressive model with gaussian noise for this inital task. Obviously, the continuous noise model with values below zero is not ideal and should be revisited if the model is to be improved. The fact that the data contains a significant number of zeros likely affects the assumption that time series data is stationary. The lag term should be optimised, but as this assessment is not about model performance I shall leave that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ba7434-fae9-4af1-99e2-fcc057dabdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise count data\n",
    "test_count_subset_bed = counted_events_per_house[(counted_events_per_house['home_id'] == 'f5a2b27c9d8bb7f59b7b0684d3555e52') & (counted_events_per_house['location'] == 'bedroom1')]['event_count']\n",
    "test_count_subset_lounge = counted_events_per_house[(counted_events_per_house['home_id'] == 'f5a2b27c9d8bb7f59b7b0684d3555e52') & (counted_events_per_house['location'] == 'lounge')]['event_count']\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1)  # Create a figure containing a single axes.\n",
    "ax[0].plot(range(31), test_count_subset_bed)  # Plot some data on the axes.\n",
    "ax[0].title.set_text(\"Bedroom1\")\n",
    "ax[1].plot(range(31), test_count_subset_lounge)  # Plot some data on the axes.\n",
    "ax[1].title.set_text(\"Lounge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f57764e-6408-4068-9dfd-9522d2ff38b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check vector autoregression model forcasts resonable results\n",
    "test_model_fit = counted_events_per_house[(counted_events_per_house['home_id'] == 'f5a2b27c9d8bb7f59b7b0684d3555e52')].pivot_table(index=\"datetime\",values=\"event_count\", columns=\"location\")\n",
    "#test_model_fit = np.log(test_model_fit)\n",
    "model = VAR(test_model_fit.iloc[0:29], freq = \"D\")\n",
    "results = model.fit(2)\n",
    "results.forecast(test_model_fit.values[28:], 2)\n",
    "results.plot_forecast(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d51d994-0dd6-465e-8cdd-0adb729190aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply model to all homes\n",
    "modelled_event_counts = counted_events_per_house.groupby(\"home_id\").apply(fit_VAR_model, lag=2, freq=\"D\", include_groups=False)\n",
    "# Move index to column names\n",
    "modelled_event_counts = modelled_event_counts.reset_index(level='home_id')\n",
    "modelled_event_counts[\"coefficient\"] = modelled_event_counts.index\n",
    "modelled_event_counts = modelled_event_counts.reset_index(drop=True)\n",
    "# Pivot all coefficients to column values and flatten column name hierchy \n",
    "modelled_event_counts = modelled_event_counts.pivot(columns=\"coefficient\", index=\"home_id\")\n",
    "modelled_event_counts.columns = [' '.join(col).strip() for col in modelled_event_counts.columns.values]\n",
    "# Set missing vector autoregression coefficients to 0\n",
    "modelled_event_counts = modelled_event_counts.fillna(0)\n",
    "# Join results with binary data to prepare for classification\n",
    "modelled_event_counts = modelled_event_counts.join(homes_with_binary_locations.set_index('home_id')).fillna(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549de08f-9e8e-4854-932c-79a8f32deed8",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c85181-1bad-4558-a38e-3022aa9b5d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcf4eed5-f1a4-4189-98bb-050b5c3a2998",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15376eb9-7c09-4281-9a2e-fceb9476f705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
